{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bcf554-7631-4942-adeb-02d90cd8d24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a750b806-2988-44a9-9b8b-60086c92ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in /Users/xrickliao/miniconda3/miniconda3/envs/salesragenv/lib/python3.11/site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573636f9-bfd2-41de-80c5-572bdd252152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 設定 ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "DUCKDB_FILE = \"sales_rag_app/db/sales_specs.db\"\n",
    "COLLECTION_NAME = \"sales_notebook_specs\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26a23d0-cde3-4347-80b5-5143e2051feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 增強版文本解析函數 ---\n",
    "def parse_spec_file_enhanced(file_path):\n",
    "    \"\"\"\n",
    "    解析包含多個模型的 .txt 規格檔案。\n",
    "    能處理針對 'All models' 或 'ModelA / ModelB:' 的規格。\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    current_section = None\n",
    "    # 從檔案名稱中提取基礎型號系列，例如從 '326_AllModels.txt' 提取 '326'\n",
    "    base_model_series = os.path.basename(file_path).split('_')[0]\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content_lines = f.readlines()\n",
    "\n",
    "    all_models_in_file = set()\n",
    "    # 第一次遍歷：找出檔案中定義的所有型號\n",
    "    for line in content_lines:\n",
    "        line = line.strip()\n",
    "        if ':' in line:\n",
    "            key, _ = map(str.strip, line.split(':', 1))\n",
    "            model_keys_raw = re.split(r' / |,|&', key)\n",
    "            potential_models = [k.strip().replace('-', '').replace(':', '') for k in model_keys_raw if k.strip()]\n",
    "            for pm in potential_models:\n",
    "                # 假設型號包含字母和數字\n",
    "                if re.search(r'[A-Z]', pm) and re.search(r'[0-9]', pm):\n",
    "                    all_models_in_file.add(pm)\n",
    "\n",
    "    # 如果檔案中沒有明確定義型號，則使用檔案名稱作為基礎型號\n",
    "    if not all_models_in_file:\n",
    "        all_models_in_file.add(base_model_series)\n",
    "\n",
    "    # 第二次遍歷：解析規格並應用到對應的型號\n",
    "    for line in content_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        section_match = re.match(r'^\\[(.*)\\]$', line)\n",
    "        if section_match:\n",
    "            current_section = section_match.group(1).strip()\n",
    "            continue\n",
    "\n",
    "        if not current_section or ':' not in line:\n",
    "            continue\n",
    "\n",
    "        key, value = map(str.strip, line.split(':', 1))\n",
    "        \n",
    "        models_affected = []\n",
    "        feature_name = key\n",
    "\n",
    "        # 檢查 key 是否為型號定義\n",
    "        model_keys_raw = re.split(r' / |,|&', key)\n",
    "        potential_models = [k.strip().replace('-', '').replace(':', '') for k in model_keys_raw if k.strip()]\n",
    "        \n",
    "        # 判斷是否為多個型號共用的規格定義行\n",
    "        is_multi_model_spec = False\n",
    "        if len(potential_models) > 1:\n",
    "            if all((pm in all_models_in_file for pm in potential_models)):\n",
    "                 models_affected = potential_models\n",
    "                 feature_name = \"Configuration\"\n",
    "                 is_multi_model_spec = True\n",
    "\n",
    "        if not is_multi_model_spec:\n",
    "            # 如果不是多型號定義行，則視為通用規格或單一特性\n",
    "            # 如果 key 是 'All models' 或在常見的通用關鍵字中，則適用於檔案內所有型號\n",
    "            if 'all models' in key.lower() or any(kw in key.lower() for kw in ['default', 'option', 'support']):\n",
    "                models_affected.extend(all_models_in_file)\n",
    "            else:\n",
    "                # 否則，也假設它適用於所有型號，除非有更明確的指示\n",
    "                 models_affected.extend(all_models_in_file)\n",
    "        \n",
    "        value_str = \", \".join(value) if isinstance(value, list) else value\n",
    "        \n",
    "        for model in set(models_affected): # 使用 set 避免重複\n",
    "            records.append({\n",
    "                \"model_name\": model,\n",
    "                \"section\": current_section,\n",
    "                \"feature\": feature_name,\n",
    "                \"value\": value_str\n",
    "            })\n",
    "            \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9288fc-0157-41d2-948b-840e276e76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def specs_to_dataframe(specs, model_name):\n",
    "#     \"\"\"將解析後的規格轉換為 DataFrame\"\"\"\n",
    "#     records = []\n",
    "#     for section, details in specs.items():\n",
    "#         if isinstance(details, dict):\n",
    "#             for feature, value in details.items():\n",
    "#                 # 將列表值轉換為字串\n",
    "#                 value_str = \", \".join(value) if isinstance(value, list) else value\n",
    "#                 records.append([model_name, section, feature, value_str])\n",
    "#     return pd.DataFrame(records, columns=['model_name', 'section', 'feature', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85016d2-38ed-4370-a570-0795263f93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在處理結構化規格資料並存入 DuckDB ---\n",
      "找到 5 個 txt 規格檔案: 819_AllModels.txt, 656_AllModels.txt, 839_AllModels.txt, 958_AllModels.txt, 326_AllModels.txt\n",
      "  -> 正在解析: 819_AllModels.txt\n",
      "  -> 正在解析: 656_AllModels.txt\n",
      "  -> 正在解析: 839_AllModels.txt\n",
      "  -> 正在解析: 958_AllModels.txt\n",
      "  -> 正在解析: 326_AllModels.txt\n",
      "成功將 23448 筆規格資料存入 DuckDB。\n",
      "\n",
      "--- 正在處理所有 .txt 文檔資料並存入 Milvus ---\n",
      "找到舊的 Collection 'sales_notebook_specs'，正在刪除...\n",
      "準備為 Milvus 處理 5 個檔案: 819_AllModels.txt, 656_AllModels.txt, 839_AllModels.txt, 958_AllModels.txt, 326_AllModels.txt\n",
      "共讀取並分割成 118 個文本區塊。\n",
      "正在產生嵌入向量...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mapleleaf/.conda/envs/salseragenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在將資料插入 Milvus...\n",
      "正在為向量創建索引 (IVF_FLAT)...\n",
      "成功將 118 筆資料導入 Milvus Collection 'sales_notebook_specs'。\n",
      "\n",
      "資料導入完成！\n"
     ]
    }
   ],
   "source": [
    "# --- 主執行流程 ---\n",
    "def main():\n",
    "    # --- 1. 處理結構化資料 (DuckDB) ---\n",
    "    print(\"--- 正在處理結構化規格資料並存入 DuckDB ---\")\n",
    "    \n",
    "    txt_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.txt')]\n",
    "    if not txt_files:\n",
    "        print(\"錯誤：在 'data' 目錄中找不到任何 .txt 檔案。請將您的 `*_AllModels.txt` 檔案放入其中。\")\n",
    "        return\n",
    "        \n",
    "    print(f\"找到 {len(txt_files)} 個 txt 規格檔案: {', '.join(txt_files)}\")\n",
    "\n",
    "    all_db_records = []\n",
    "    for filename in txt_files:\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        print(f\"  -> 正在解析: {filename}\")\n",
    "        records = parse_spec_file_enhanced(file_path)\n",
    "        all_db_records.extend(records)\n",
    "\n",
    "    if not all_db_records:\n",
    "        print(\"警告：未從 .txt 檔案中解析出任何結構化資料。\")\n",
    "    else:\n",
    "        final_df = pd.DataFrame(all_db_records).drop_duplicates()\n",
    "        \n",
    "        if os.path.exists(DUCKDB_FILE):\n",
    "            os.remove(DUCKDB_FILE)\n",
    "        con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "        con.execute(\"CREATE TABLE specs AS SELECT * FROM final_df\")\n",
    "        print(f\"成功將 {len(final_df)} 筆規格資料存入 DuckDB。\")\n",
    "        con.close()\n",
    "\n",
    "    # --- 2. 處理所有 .txt 文件以進行語意搜尋 (Milvus) ---\n",
    "    print(\"\\n--- 正在處理所有 .txt 文檔資料並存入 Milvus ---\")\n",
    "    connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "    if utility.has_collection(COLLECTION_NAME):\n",
    "        print(f\"找到舊的 Collection '{COLLECTION_NAME}'，正在刪除...\")\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "    fields = [\n",
    "        FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),\n",
    "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=200),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields, \"銷售筆電規格知識庫\")\n",
    "    collection = Collection(COLLECTION_NAME, schema)\n",
    "    \n",
    "    all_milvus_docs = []\n",
    "    # 這次只處理 .txt 檔案\n",
    "    files_to_process_milvus = [f for f in os.listdir(DATA_DIR) if f.endswith('.txt')]\n",
    "    print(f\"準備為 Milvus 處理 {len(files_to_process_milvus)} 個檔案: {', '.join(files_to_process_milvus)}\")\n",
    "\n",
    "    for filename in files_to_process_milvus:\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            chunks = text_splitter.split_text(content)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_milvus_docs.append({\n",
    "                    \"pk\": f\"{filename}_{i}\",\n",
    "                    \"text\": chunk,\n",
    "                    \"source\": filename\n",
    "                })\n",
    "\n",
    "    print(f\"共讀取並分割成 {len(all_milvus_docs)} 個文本區塊。\")\n",
    "\n",
    "    if not all_milvus_docs:\n",
    "        print(\"警告：沒有要存入 Milvus 的資料。\")\n",
    "        connections.disconnect(\"default\")\n",
    "        return\n",
    "\n",
    "    print(\"正在產生嵌入向量...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    texts_to_embed = [doc['text'] for doc in all_milvus_docs]\n",
    "    vectors = embeddings.embed_documents(texts_to_embed)\n",
    "\n",
    "    entities = [\n",
    "        [doc['pk'] for doc in all_milvus_docs],\n",
    "        [doc['text'] for doc in all_milvus_docs],\n",
    "        [doc['source'] for doc in all_milvus_docs],\n",
    "        vectors\n",
    "    ]\n",
    "\n",
    "    print(\"正在將資料插入 Milvus...\")\n",
    "    collection.insert(entities)\n",
    "    collection.flush()\n",
    "\n",
    "    print(\"正在為向量創建索引 (IVF_FLAT)...\")\n",
    "    index_params = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128}\n",
    "    }\n",
    "    collection.create_index(\"embedding\", index_params)\n",
    "    collection.load()\n",
    "\n",
    "    print(f\"成功將 {len(all_milvus_docs)} 筆資料導入 Milvus Collection '{COLLECTION_NAME}'。\")\n",
    "    print(\"\\n資料導入完成！\")\n",
    "    connections.disconnect(\"default\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9969675-5260-4554-9f77-56d643d93734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c024b-f684-45ac-9aa2-562c61a3800d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdf6e4-b6a8-4add-ac6b-438dc37ea249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# --- 設定 ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "DUCKDB_FILE = \"sales_rag_app/db/sales_specs.db\"\n",
    "COLLECTION_NAME = \"sales_notebook_specs\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# --- 增強版文本解析函數 ---\n",
    "def parse_spec_file_enhanced(file_path):\n",
    "    \"\"\"\n",
    "    解析包含多個模型的 .txt 規格檔案。\n",
    "    能處理針對 'All models' 或 'ModelA / ModelB:' 的規格。\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    current_section = None\n",
    "    # 從檔案名稱中提取基礎型號系列，例如從 '326_AllModels.txt' 提取 '326'\n",
    "    base_model_series = os.path.basename(file_path).split('_')[0]\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content_lines = f.readlines()\n",
    "\n",
    "    all_models_in_file = set()\n",
    "    # 第一次遍歷：找出檔案中定義的所有型號\n",
    "    for line in content_lines:\n",
    "        line = line.strip()\n",
    "        if ':' in line:\n",
    "            key, _ = map(str.strip, line.split(':', 1))\n",
    "            model_keys_raw = re.split(r' / |,|&', key)\n",
    "            potential_models = [k.strip().replace('-', '').replace(':', '') for k in model_keys_raw if k.strip()]\n",
    "            for pm in potential_models:\n",
    "                # 假設型號包含字母和數字\n",
    "                if re.search(r'[A-Z]', pm) and re.search(r'[0-9]', pm):\n",
    "                    all_models_in_file.add(pm)\n",
    "\n",
    "    # 如果檔案中沒有明確定義型號，則使用檔案名稱作為基礎型號\n",
    "    if not all_models_in_file:\n",
    "        all_models_in_file.add(base_model_series)\n",
    "\n",
    "    # 第二次遍歷：解析規格並應用到對應的型號\n",
    "    for line in content_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        section_match = re.match(r'^\\[(.*)\\]$', line)\n",
    "        if section_match:\n",
    "            current_section = section_match.group(1).strip()\n",
    "            continue\n",
    "\n",
    "        if not current_section or ':' not in line:\n",
    "            continue\n",
    "\n",
    "        key, value = map(str.strip, line.split(':', 1))\n",
    "        \n",
    "        models_affected = []\n",
    "        feature_name = key\n",
    "\n",
    "        # 檢查 key 是否為型號定義\n",
    "        model_keys_raw = re.split(r' / |,|&', key)\n",
    "        potential_models = [k.strip().replace('-', '').replace(':', '') for k in model_keys_raw if k.strip()]\n",
    "        \n",
    "        # 判斷是否為多個型號共用的規格定義行\n",
    "        is_multi_model_spec = False\n",
    "        if len(potential_models) > 1:\n",
    "            if all((pm in all_models_in_file for pm in potential_models)):\n",
    "                 models_affected = potential_models\n",
    "                 feature_name = \"Configuration\"\n",
    "                 is_multi_model_spec = True\n",
    "\n",
    "        if not is_multi_model_spec:\n",
    "            # 如果不是多型號定義行，則視為通用規格或單一特性\n",
    "            # 如果 key 是 'All models' 或在常見的通用關鍵字中，則適用於檔案內所有型號\n",
    "            if 'all models' in key.lower() or any(kw in key.lower() for kw in ['default', 'option', 'support']):\n",
    "                models_affected.extend(all_models_in_file)\n",
    "            else:\n",
    "                # 否則，也假設它適用於所有型號，除非有更明確的指示\n",
    "                 models_affected.extend(all_models_in_file)\n",
    "        \n",
    "        value_str = \", \".join(value) if isinstance(value, list) else value\n",
    "        \n",
    "        for model in set(models_affected): # 使用 set 避免重複\n",
    "            records.append({\n",
    "                \"model_name\": model,\n",
    "                \"section\": current_section,\n",
    "                \"feature\": feature_name,\n",
    "                \"value\": value_str\n",
    "            })\n",
    "            \n",
    "    return records\n",
    "\n",
    "\n",
    "# --- 主執行流程 ---\n",
    "def main():\n",
    "    # --- 1. 處理結構化資料 (DuckDB) ---\n",
    "    print(\"--- 正在處理結構化規格資料並存入 DuckDB ---\")\n",
    "    \n",
    "    txt_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.txt')]\n",
    "    if not txt_files:\n",
    "        print(\"錯誤：在 'data' 目錄中找不到任何 .txt 檔案。請將您的 `*_AllModels.txt` 檔案放入其中。\")\n",
    "        return\n",
    "        \n",
    "    print(f\"找到 {len(txt_files)} 個 txt 規格檔案: {', '.join(txt_files)}\")\n",
    "\n",
    "    all_db_records = []\n",
    "    for filename in txt_files:\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        print(f\"  -> 正在解析: {filename}\")\n",
    "        records = parse_spec_file_enhanced(file_path)\n",
    "        all_db_records.extend(records)\n",
    "\n",
    "    if not all_db_records:\n",
    "        print(\"警告：未從 .txt 檔案中解析出任何結構化資料。\")\n",
    "    else:\n",
    "        final_df = pd.DataFrame(all_db_records).drop_duplicates()\n",
    "        \n",
    "        if os.path.exists(DUCKDB_FILE):\n",
    "            os.remove(DUCKDB_FILE)\n",
    "        con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "        con.execute(\"CREATE TABLE specs AS SELECT * FROM final_df\")\n",
    "        print(f\"成功將 {len(final_df)} 筆規格資料存入 DuckDB。\")\n",
    "        con.close()\n",
    "\n",
    "    # --- 2. 處理所有 .txt 文件以進行語意搜尋 (Milvus) ---\n",
    "    print(\"\\n--- 正在處理所有 .txt 文檔資料並存入 Milvus ---\")\n",
    "    connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "    if utility.has_collection(COLLECTION_NAME):\n",
    "        print(f\"找到舊的 Collection '{COLLECTION_NAME}'，正在刪除...\")\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "    fields = [\n",
    "        FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),\n",
    "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=200),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields, \"銷售筆電規格知識庫\")\n",
    "    collection = Collection(COLLECTION_NAME, schema)\n",
    "    \n",
    "    all_milvus_docs = []\n",
    "    # 這次只處理 .txt 檔案\n",
    "    files_to_process_milvus = [f for f in os.listdir(DATA_DIR) if f.endswith('.txt')]\n",
    "    print(f\"準備為 Milvus 處理 {len(files_to_process_milvus)} 個檔案: {', '.join(files_to_process_milvus)}\")\n",
    "\n",
    "    for filename in files_to_process_milvus:\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            chunks = text_splitter.split_text(content)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_milvus_docs.append({\n",
    "                    \"pk\": f\"{filename}_{i}\",\n",
    "                    \"text\": chunk,\n",
    "                    \"source\": filename\n",
    "                })\n",
    "\n",
    "    print(f\"共讀取並分割成 {len(all_milvus_docs)} 個文本區塊。\")\n",
    "\n",
    "    if not all_milvus_docs:\n",
    "        print(\"警告：沒有要存入 Milvus 的資料。\")\n",
    "        connections.disconnect(\"default\")\n",
    "        return\n",
    "\n",
    "    print(\"正在產生嵌入向量...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    texts_to_embed = [doc['text'] for doc in all_milvus_docs]\n",
    "    vectors = embeddings.embed_documents(texts_to_embed)\n",
    "\n",
    "    entities = [\n",
    "        [doc['pk'] for doc in all_milvus_docs],\n",
    "        [doc['text'] for doc in all_milvus_docs],\n",
    "        [doc['source'] for doc in all_milvus_docs],\n",
    "        vectors\n",
    "    ]\n",
    "\n",
    "    print(\"正在將資料插入 Milvus...\")\n",
    "    collection.insert(entities)\n",
    "    collection.flush()\n",
    "\n",
    "    print(\"正在為向量創建索引 (IVF_FLAT)...\")\n",
    "    index_params = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128}\n",
    "    }\n",
    "    collection.create_index(\"embedding\", index_params)\n",
    "    collection.load()\n",
    "\n",
    "    print(f\"成功將 {len(all_milvus_docs)} 筆資料導入 Milvus Collection '{COLLECTION_NAME}'。\")\n",
    "    print(\"\\n資料導入完成！\")\n",
    "    connections.disconnect(\"default\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
