{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "好的，這就為您提供整個「AI 筆記型電腦銷售助理」專案的完整程式碼。\n",
        "\n",
        "為了讓您能直接使用，我將依照專案的目錄結構，提供每一個檔案的完整內容。\n",
        "\n",
        "-----\n",
        "\n",
        "### \\#\\# 專案目錄結構\n",
        "\n",
        "在開始之前，請先建立以下的目錄與檔案結構：\n",
        "\n",
        "```\n",
        "sales_rag_project/\n",
        "├── data/                      # 放置原始資料檔案\n",
        "│   ├── AG958.txt\n",
        "│   ├── AKK839.txt\n",
        "│   └── AG958 與 AKK839 筆記型電腦規格對照分析.md\n",
        "│\n",
        "├── sales_rag_app/             # 主要應用程式目錄\n",
        "│   ├── db/                    # 存放資料庫檔案\n",
        "│   │   └── sales_specs.db\n",
        "│   ├── libs/\n",
        "│   │   ├── RAG/\n",
        "│   │   │   ├── DB/\n",
        "│   │   │   │   ├── DatabaseQuery.py\n",
        "│   │   │   │   ├── DuckDBQuery.py\n",
        "│   │   │   │   └── MilvusQuery.py\n",
        "│   │   │   ├── LLM/\n",
        "│   │   │   │   └── LLMInitializer.py\n",
        "│   │   │   └── Tools/\n",
        "│   │   │       └── ContentSpliter.py\n",
        "│   │   ├── services/\n",
        "│   │   │   ├── base_service.py\n",
        "│   │   │   └── sales_assistant/\n",
        "│   │   │       ├── service.py\n",
        "│   │   │       └── prompts/\n",
        "│   │   │           └── sales_prompt.txt\n",
        "│   │   └── service_manager.py\n",
        "│   ├── static/\n",
        "│   │   ├── css/\n",
        "│   │   │   └── style.css\n",
        "│   │   └── js/\n",
        "│   │       ├── ai-chat.js\n",
        "│   │       └── marked.min.js\n",
        "│   ├── templates/\n",
        "│   │   ├── chat/\n",
        "│   │   │   └── ai-chat-content.html\n",
        "│   │   └── index.html\n",
        "│   └── main.py\n",
        "│\n",
        "├── docker-compose.yml         # Docker 服務設定\n",
        "├── ingest_data.py             # 資料導入腳本\n",
        "└── requirements.txt           # Python 套件依賴\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### \\#\\# 1. Docker & 環境設定\n",
        "\n",
        "#### **`docker-compose.yml`**\n",
        "\n",
        "此檔案用於啟動 Milvus 向量資料庫。\n",
        "\n",
        "```yaml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  etcd:\n",
        "    image: quay.io/coreos/etcd:v3.5.9\n",
        "    environment:\n",
        "      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379\n",
        "      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379\n",
        "    command: >\n",
        "      etcd -advertise-client-urls http://etcd:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd\n",
        "    volumes:\n",
        "      - ./etcd-data:/etcd\n",
        "    ports:\n",
        "      - \"2379:2379\"\n",
        "\n",
        "  minio:\n",
        "    image: minio/minio:RELEASE.2023-09-07T22-52-08Z\n",
        "    environment:\n",
        "      - MINIO_ROOT_USER=minioadmin\n",
        "      - MINIO_ROOT_PASSWORD=minioadmin\n",
        "    command: minio server /minio_data --console-address \":9001\"\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "      - \"9001:9001\"\n",
        "    volumes:\n",
        "      - ./minio-data:/minio_data\n",
        "\n",
        "  milvus:\n",
        "    image: milvusdb/milvus:v2.4.4-cpu\n",
        "    depends_on:\n",
        "      - etcd\n",
        "      - minio\n",
        "    environment:\n",
        "      - ETCD_ENDPOINTS=etcd:2379\n",
        "      - MINIO_ADDRESS=minio:9000\n",
        "    ports:\n",
        "      - \"19530:19530\"\n",
        "    command: milvus run\n",
        "    volumes:\n",
        "      - ./milvus-data:/var/lib/milvus\n",
        "```\n",
        "\n",
        "#### **`requirements.txt`**\n",
        "\n",
        "這是專案所需的所有 Python 套件。\n",
        "\n",
        "```\n",
        "fastapi\n",
        "uvicorn[standard]\n",
        "python-dotenv\n",
        "langchain\n",
        "langchain-community\n",
        "sentence-transformers\n",
        "pymilvus\n",
        "duckdb\n",
        "pandas\n",
        "jinja2\n",
        "python-multipart\n",
        "requests\n",
        "beautifulsoup4\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### \\#\\# 2. 資料導入腳本\n",
        "\n",
        "這個腳本只需執行一次，用於處理您的資料並存入 Milvus 和 DuckDB。\n",
        "\n",
        "#### **`ingest_data.py`**"
      ],
      "metadata": {
        "id": "Uojqct63Vmo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# --- 設定 ---\n",
        "MILVUS_HOST = \"localhost\"\n",
        "MILVUS_PORT = \"19530\"\n",
        "DUCKDB_FILE = \"sales_rag_app/db/sales_specs.db\"\n",
        "COLLECTION_NAME = \"sales_notebook_specs\"\n",
        "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
        "DATA_DIR = \"data\"\n",
        "\n",
        "# --- 文本解析函數 ---\n",
        "def parse_spec_file(file_path):\n",
        "    \"\"\"解析 .txt 規格檔案，提取鍵值對\"\"\"\n",
        "    specs = {}\n",
        "    current_section = None\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            section_match = re.match(r'^\\[(.*)\\]$', line)\n",
        "            if section_match:\n",
        "                current_section = section_match.group(1)\n",
        "                specs[current_section] = {}\n",
        "            elif ':' in line and current_section:\n",
        "                key, value = map(str.strip, line.split(':', 1))\n",
        "                if key in specs[current_section]:\n",
        "                    # 處理重複的鍵，例如 Options\n",
        "                    if isinstance(specs[current_section][key], list):\n",
        "                        specs[current_section][key].append(value)\n",
        "                    else:\n",
        "                        specs[current_section][key] = [specs[current_section][key], value]\n",
        "                else:\n",
        "                    specs[current_section][key] = value\n",
        "    return specs\n",
        "\n",
        "def specs_to_dataframe(specs, model_name):\n",
        "    \"\"\"將解析後的規格轉換為 DataFrame\"\"\"\n",
        "    records = []\n",
        "    for section, details in specs.items():\n",
        "        if isinstance(details, dict):\n",
        "            for feature, value in details.items():\n",
        "                # 將列表值轉換為字串\n",
        "                value_str = \", \".join(value) if isinstance(value, list) else value\n",
        "                records.append([model_name, section, feature, value_str])\n",
        "    return pd.DataFrame(records, columns=['model_name', 'section', 'feature', 'value'])\n",
        "\n",
        "# --- 主執行流程 ---\n",
        "def main():\n",
        "    # --- 1. 處理結構化資料 (DuckDB) ---\n",
        "    print(\"--- 正在處理結構化規格資料並存入 DuckDB ---\")\n",
        "    if os.path.exists(DUCKDB_FILE):\n",
        "        os.remove(DUCKDB_FILE)\n",
        "\n",
        "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
        "\n",
        "    ag958_specs = parse_spec_file(os.path.join(DATA_DIR, \"AG958.txt\"))\n",
        "    akk839_specs = parse_spec_file(os.path.join(DATA_DIR, \"AKK839.txt\"))\n",
        "\n",
        "    df_ag958 = specs_to_dataframe(ag958_specs, \"AG958\")\n",
        "    df_akk839 = specs_to_dataframe(akk839_specs, \"AKK839\")\n",
        "\n",
        "    df_total = pd.concat([df_ag958, df_akk839], ignore_index=True)\n",
        "\n",
        "    con.execute(\"CREATE TABLE specs AS SELECT * FROM df_total\")\n",
        "    print(f\"成功將 {len(df_total)} 筆規格資料存入 DuckDB。\")\n",
        "    con.close()\n",
        "\n",
        "    # --- 2. 處理非結構化資料 (Milvus) ---\n",
        "    print(\"\\n--- 正在處理文本資料並存入 Milvus ---\")\n",
        "    connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "\n",
        "    if utility.has_collection(COLLECTION_NAME):\n",
        "        print(f\"找到舊的 Collection '{COLLECTION_NAME}'，正在刪除...\")\n",
        "        utility.drop_collection(COLLECTION_NAME)\n",
        "\n",
        "    # 定義 Collection Schema\n",
        "    fields = [\n",
        "        FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),\n",
        "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
        "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=200),\n",
        "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
        "    ]\n",
        "    schema = CollectionSchema(fields, \"銷售筆電規格知識庫\")\n",
        "    collection = Collection(COLLECTION_NAME, schema)\n",
        "\n",
        "    # 讀取所有文件\n",
        "    all_docs = []\n",
        "    for filename in os.listdir(DATA_DIR):\n",
        "        file_path = os.path.join(DATA_DIR, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "            # 使用 LangChain 的 TextSplitter\n",
        "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "            chunks = text_splitter.split_text(content)\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                all_docs.append({\n",
        "                    \"pk\": f\"{filename}_{i}\",\n",
        "                    \"text\": chunk,\n",
        "                    \"source\": filename\n",
        "                })\n",
        "\n",
        "    print(f\"共讀取並分割成 {len(all_docs)} 個文本區塊。\")\n",
        "\n",
        "    # 產生嵌入向量\n",
        "    print(\"正在產生嵌入向量...\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
        "    texts_to_embed = [doc['text'] for doc in all_docs]\n",
        "    vectors = embeddings.embed_documents(texts_to_embed)\n",
        "\n",
        "    # 準備插入 Milvus 的資料\n",
        "    entities = [\n",
        "        [doc['pk'] for doc in all_docs],\n",
        "        [doc['text'] for doc in all_docs],\n",
        "        [doc['source'] for doc in all_docs],\n",
        "        vectors\n",
        "    ]\n",
        "\n",
        "    # 插入資料\n",
        "    print(\"正在將資料插入 Milvus...\")\n",
        "    collection.insert(entities)\n",
        "    collection.flush()\n",
        "\n",
        "    # 創建索引\n",
        "    print(\"正在為向量創建索引 (IVF_FLAT)...\")\n",
        "    index_params = {\n",
        "        \"metric_type\": \"L2\",\n",
        "        \"index_type\": \"IVF_FLAT\",\n",
        "        \"params\": {\"nlist\": 128}\n",
        "    }\n",
        "    collection.create_index(\"embedding\", index_params)\n",
        "    collection.load()\n",
        "\n",
        "    print(f\"成功將 {len(all_docs)} 筆資料導入 Milvus Collection '{COLLECTION_NAME}'。\")\n",
        "    print(\"\\n資料導入完成！\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xk-EWLf1Vmo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### \\#\\# 3. 後端應用程式 (FastAPI)\n",
        "\n",
        "#### **`sales_rag_app/main.py`**"
      ],
      "metadata": {
        "id": "z4yCvmxjVmo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import HTMLResponse, StreamingResponse, JSONResponse\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from libs.service_manager import ServiceManager\n",
        "\n",
        "# 載入環境變數\n",
        "load_dotenv()\n",
        "\n",
        "# 初始化 FastAPI 應用\n",
        "app = FastAPI()\n",
        "\n",
        "# 掛載靜態檔案目錄\n",
        "app.mount(\"/static\", StaticFiles(directory=\"sales_rag_app/static\"), name=\"static\")\n",
        "\n",
        "# 設定模板目錄\n",
        "templates = Jinja2Templates(directory=\"sales_rag_app/templates\")\n",
        "\n",
        "# 初始化服務管理器\n",
        "service_manager = ServiceManager()\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root(request: Request):\n",
        "    \"\"\"渲染主頁面\"\"\"\n",
        "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
        "\n",
        "@app.get(\"/api/get-services\", response_class=JSONResponse)\n",
        "async def get_services():\n",
        "    \"\"\"獲取可用的服務列表\"\"\"\n",
        "    services = service_manager.list_services()\n",
        "    return {\"services\": services}\n",
        "\n",
        "@app.post(\"/api/chat-stream\")\n",
        "async def chat_stream(request: Request):\n",
        "    \"\"\"處理聊天請求並返回流式響應\"\"\"\n",
        "    try:\n",
        "        data = await request.json()\n",
        "        query = data.get(\"query\")\n",
        "        service_name = data.get(\"service_name\", \"sales_assistant\") # 預設使用銷售助理\n",
        "\n",
        "        if not query:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Query cannot be empty\"})\n",
        "\n",
        "        service = service_manager.get_service(service_name)\n",
        "        if not service:\n",
        "             return JSONResponse(status_code=404, content={\"error\": f\"Service '{service_name}' not found\"})\n",
        "\n",
        "        # 返回一個流式響應，從服務的 chat_stream 方法獲取內容\n",
        "        return StreamingResponse(service.chat_stream(query), media_type=\"text/event-stream\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_stream: {e}\")\n",
        "        return JSONResponse(status_code=500, content={\"error\": \"Internal Server Error\"})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "D0buUxOAVmo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/service_manager.py`**"
      ],
      "metadata": {
        "id": "MGqjbbm4Vmo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import os\n",
        "\n",
        "from .services.base_service import BaseService\n",
        "\n",
        "class ServiceManager:\n",
        "    def __init__(self, service_directory=\"sales_rag_app/libs/services\"):\n",
        "        self.services = {}\n",
        "        self._discover_services(service_directory)\n",
        "\n",
        "    def _discover_services(self, service_directory):\n",
        "        \"\"\"動態發現並載入所有服務\"\"\"\n",
        "        for service_name in os.listdir(service_directory):\n",
        "            service_path = os.path.join(service_directory, service_name)\n",
        "            if os.path.isdir(service_path) and service_name != \"__pycache__\":\n",
        "                try:\n",
        "                    # 動態導入 service.py 模組\n",
        "                    module_path = f\"sales_rag_app.libs.services.{service_name}.service\"\n",
        "                    service_module = importlib.import_module(module_path)\n",
        "\n",
        "                    # 在模組中尋找繼承自 BaseService 的類別\n",
        "                    for attr_name in dir(service_module):\n",
        "                        attr = getattr(service_module, attr_name)\n",
        "                        if isinstance(attr, type) and issubclass(attr, BaseService) and attr is not BaseService:\n",
        "                            self.services[service_name] = attr()\n",
        "                            print(f\"成功載入服務: {service_name}\")\n",
        "                            break\n",
        "                except (ImportError, AttributeError, FileNotFoundError) as e:\n",
        "                    print(f\"無法載入服務 '{service_name}': {e}\")\n",
        "\n",
        "    def get_service(self, service_name: str) -> BaseService:\n",
        "        \"\"\"根據名稱獲取服務實例\"\"\"\n",
        "        return self.services.get(service_name)\n",
        "\n",
        "    def list_services(self) -> list:\n",
        "        \"\"\"返回所有已載入服務的名稱列表\"\"\"\n",
        "        return list(self.services.keys())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "uq8Ktq9iVmo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/services/base_service.py`**"
      ],
      "metadata": {
        "id": "AFcpAAFNVmpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class BaseService(ABC):\n",
        "    @abstractmethod\n",
        "    def chat_stream(self, query: str, **kwargs):\n",
        "        \"\"\"\n",
        "        處理聊天請求並以流式方式返回結果。\n",
        "        必須是一個生成器 (generator)。\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "EEDhI6HRVmpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/services/sales_assistant/service.py`**\n",
        "\n",
        "`"
      ],
      "metadata": {
        "id": "q5dEODzKVmpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from ..base_service import BaseService\n",
        "from ...RAG.DB.MilvusQuery import MilvusQuery\n",
        "from ...RAG.DB.DuckDBQuery import DuckDBQuery\n",
        "from ...RAG.LLM.LLMInitializer import LLMInitializer\n",
        "\n",
        "class SalesAssistantService(BaseService):\n",
        "    def __init__(self):\n",
        "        # 初始化 LLM\n",
        "        self.llm = LLMInitializer().get_llm()\n",
        "\n",
        "        # 初始化資料庫查詢器\n",
        "        self.milvus_query = MilvusQuery(collection_name=\"sales_notebook_specs\")\n",
        "        self.duckdb_query = DuckDBQuery(db_file=\"sales_rag_app/db/sales_specs.db\")\n",
        "\n",
        "        # 載入提示模板\n",
        "        self.prompt_template = self._load_prompt_template(\"sales_rag_app/libs/services/sales_assistant/prompts/sales_prompt.txt\")\n",
        "\n",
        "    def _load_prompt_template(self, path: str) -> PromptTemplate:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            template_str = f.read()\n",
        "        return PromptTemplate.from_template(template_str)\n",
        "\n",
        "    def _get_structured_specs(self, keywords: list) -> dict:\n",
        "        \"\"\"從 DuckDB 查詢結構化資料\"\"\"\n",
        "        specs = {}\n",
        "        for keyword in keywords:\n",
        "            query_sql = f\"SELECT model_name, feature, value FROM specs WHERE feature ILIKE '%{keyword}%' OR value ILIKE '%{keyword}%'\"\n",
        "            results = self.duckdb_query.query(query_sql)\n",
        "            if results:\n",
        "                for row in results:\n",
        "                    feature_key = f\"{row[1]} ({row[0]})\" # e.g. \"TDP (AG958)\"\n",
        "                    specs[feature_key] = row[2]\n",
        "        return specs\n",
        "\n",
        "    async def chat_stream(self, query: str, **kwargs):\n",
        "        \"\"\"執行完整的 RAG 流程\"\"\"\n",
        "        try:\n",
        "            # 1. 知識檢索\n",
        "            # 從 Milvus 進行語意搜尋\n",
        "            retrieved_docs = self.milvus_query.search(query, top_k=5)\n",
        "            semantic_context = \"\\n---\\n\".join([f\"Source: {doc['source']}\\nContent: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "            # 從 DuckDB 進行關鍵字查詢\n",
        "            # (簡易的關鍵字提取，實際應用可更複雜)\n",
        "            keywords_to_check = [\"TDP\", \"CPU\", \"RAM\", \"Weight\", \"Dimensions\", \"Battery\", \"Wi-Fi\"]\n",
        "            found_keywords = [kw for kw in keywords_to_check if kw.lower() in query.lower()]\n",
        "            structured_context_dict = self._get_structured_specs(found_keywords)\n",
        "            structured_context = \"\\n\".join([f\"- {k}: {v}\" for k, v in structured_context_dict.items()])\n",
        "\n",
        "            # 2. 上下文組合\n",
        "            final_context = f\"### 相關文件片段 (語意搜尋結果):\\n{semantic_context}\\n\\n\"\n",
        "            if structured_context:\n",
        "                final_context += f\"### 精確規格資料 (關鍵字查詢結果):\\n{structured_context}\"\n",
        "\n",
        "            # 3. 建構提示\n",
        "            final_prompt = self.prompt_template.format(context=final_context, query=query)\n",
        "\n",
        "            print(\"--- FINAL PROMPT ---\")\n",
        "            print(final_prompt)\n",
        "            print(\"--------------------\")\n",
        "\n",
        "            # 4. LLM 互動與串流\n",
        "            response_str = self.llm.invoke(final_prompt)\n",
        "\n",
        "            # 嘗試解析 LLM 回傳的字串為 JSON\n",
        "            try:\n",
        "                # LLM 可能回傳被 Markdown 包裹的 JSON，需要清理\n",
        "                cleaned_response_str = response_str.strip().removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
        "                parsed_json = json.loads(cleaned_response_str)\n",
        "                # 使用 Server-Sent Events (SSE) 格式回傳完整的 JSON 物件\n",
        "                yield f\"data: {json.dumps(parsed_json, ensure_ascii=False)}\\n\\n\"\n",
        "            except json.JSONDecodeError:\n",
        "                # 如果 LLM 沒有回傳標準 JSON，則將其包裝在一個錯誤物件中回傳\n",
        "                error_obj = {\n",
        "                    \"answer_summary\": \"抱歉，AI 回應的格式不正確，無法解析。\",\n",
        "                    \"comparison_table\": [],\n",
        "                    \"conclusion\": \"請稍後再試或調整您的問題。\",\n",
        "                    \"source_references\": [f\"Raw response from AI: {response_str}\"]\n",
        "                }\n",
        "                yield f\"data: {json.dumps(error_obj, ensure_ascii=False)}\\n\\n\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in SalesAssistantService.chat_stream: {e}\")\n",
        "            error_obj = {\"error\": \"An unexpected error occurred in the service.\"}\n",
        "            yield f\"data: {json.dumps(error_obj, ensure_ascii=False)}\\n\\n\"\n",
        "````\n",
        "\n",
        "#### **`sales_rag_app/libs/services/sales_assistant/prompts/sales_prompt.txt`**\n",
        "\n",
        "````text\n",
        "### SYSTEM PROMPT ###\n",
        "你是一位頂級的筆記型電腦技術銷售專家。你的任務是根據提供的「上下文資料」，精確、客觀地回答使用者關於 AG958 和 AKK839 這兩款筆記型電腦的問題。\n",
        "\n",
        "### 指令 ###\n",
        "1.  **角色扮演**：始終以專業、自信的銷售專家口吻回答。\n",
        "2.  **資料來源**：你的所有回答都「必須」嚴格基於提供的「上下文資料」。上下文中可能包含「規格文件」和「分析文件」。嚴禁回答任何在上下文中找不到的資訊。如果資料不足，請直接回答「根據我目前的資料，無法回答這個問題。」\n",
        "3.  **比較問題**：如果使用者提出比較性的問題 (例如「哪台比較好」、「有什麼不同」)，你必須同時列出兩台機型的相關規格，並根據數據進行客觀比較。\n",
        "4.  **單一模型問題**：如果使用者只問單一機型，請專注回答該機型的資訊，但如果上下文中包含與另一機型的對比，可以適度提及以突顯其特點。\n",
        "5.  **輸出格式**：你的回答「必須」是一個完整的、格式正確的 JSON 物件，不得包含任何 JSON 格式以外的文字 (例如 \"Here is the JSON:\" 或 Markdown 的 ```json 標籤)。JSON 結構如下：\n",
        "\n",
        "{\n",
        "  \"answer_summary\": \"對使用者問題的總結性回答，以自然語言呈現，應簡潔明瞭。\",\n",
        "  \"comparison_table\": [\n",
        "    {\n",
        "      \"feature\": \"比較的特性 (例如 '散熱設計')\",\n",
        "      \"AG958\": \"AG958 在此特性上的規格或描述\",\n",
        "      \"AKK839\": \"AKK839 在此特性上的規格或描述\"\n",
        "    },\n",
        "    {\n",
        "      \"feature\": \"CPU 型號\",\n",
        "      \"AG958\": \"AMD Ryzen 9 6900HX\",\n",
        "      \"AKK839\": \"AMD Ryzen 9 8945HS\"\n",
        "    }\n",
        "  ],\n",
        "  \"conclusion\": \"基於比較後的專家結論或建議。例如：'如果您追求極致的遊戲性能，AG958 更適合；若您需要兼顧效能與便攜性，AKK839 是不錯的選擇。'\",\n",
        "  \"source_references\": [\n",
        "    \"來源文件的片段一...\",\n",
        "    \"來源文件的片段二...\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "### 上下文資料 ###\n",
        "---\n",
        "{context}\n",
        "---\n",
        "\n",
        "### 使用者問題 ###\n",
        "{query}\n",
        "\n",
        "### 你的 JSON 回答 ###\n",
        "````\n",
        "\n",
        "#### **`sales_rag_app/libs/RAG/DB/DatabaseQuery.py`**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class DatabaseQuery(ABC):\n",
        "    @abstractmethod\n",
        "    def connect(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def query(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def disconnect(self):\n",
        "        raise NotImplementedError"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "p0enPbv2VmpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/RAG/DB/DuckDBQuery.py`**"
      ],
      "metadata": {
        "id": "z801RvZ0VmpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "from .DatabaseQuery import DatabaseQuery\n",
        "\n",
        "class DuckDBQuery(DatabaseQuery):\n",
        "    def __init__(self, db_file: str):\n",
        "        self.db_file = db_file\n",
        "        self.connection = None\n",
        "        self.connect()\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            self.connection = duckdb.connect(database=self.db_file, read_only=True)\n",
        "            print(f\"成功連接到 DuckDB: {self.db_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"連接 DuckDB 失敗: {e}\")\n",
        "            self.connection = None\n",
        "\n",
        "    def query(self, sql_query: str):\n",
        "        if not self.connection:\n",
        "            print(\"DuckDB 未連接。\")\n",
        "            return None\n",
        "        try:\n",
        "            return self.connection.execute(sql_query).fetchall()\n",
        "        except Exception as e:\n",
        "            print(f\"DuckDB 查詢失敗: {e}\")\n",
        "            return None\n",
        "\n",
        "    def disconnect(self):\n",
        "        if self.connection:\n",
        "            self.connection.close()\n",
        "            self.connection = None\n",
        "            print(\"已斷開 DuckDB 連接。\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "WS79kDMgVmpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/RAG/DB/MilvusQuery.py`**"
      ],
      "metadata": {
        "id": "6CK1efctVmpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import connections, utility, Collection\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from .DatabaseQuery import DatabaseQuery\n",
        "\n",
        "class MilvusQuery(DatabaseQuery):\n",
        "    def __init__(self, host=\"localhost\", port=\"19530\", collection_name=None):\n",
        "        self.host = host\n",
        "        self.port = port\n",
        "        self.collection_name = collection_name\n",
        "        self.collection = None\n",
        "        self.embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "        self.connect()\n",
        "        if self.collection_name:\n",
        "            self.set_collection(collection_name)\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            connections.connect(\"default\", host=self.host, port=self.port)\n",
        "            print(f\"成功連接到 Milvus at {self.host}:{self.port}\")\n",
        "        except Exception as e:\n",
        "            print(f\"連接 Milvus 失敗: {e}\")\n",
        "\n",
        "    def set_collection(self, collection_name: str):\n",
        "        try:\n",
        "            if utility.has_collection(collection_name):\n",
        "                self.collection = Collection(collection_name)\n",
        "                self.collection.load()\n",
        "                self.collection_name = collection_name\n",
        "                print(f\"成功設定並載入 Collection: {collection_name}\")\n",
        "            else:\n",
        "                print(f\"錯誤: Collection '{collection_name}' 不存在。\")\n",
        "                self.collection = None\n",
        "        except Exception as e:\n",
        "            print(f\"設定 Collection 失敗: {e}\")\n",
        "\n",
        "    def search(self, query_text: str, top_k=5):\n",
        "        if not self.collection:\n",
        "            print(\"錯誤: 未設定 Collection。\")\n",
        "            return []\n",
        "\n",
        "        # 1. 將查詢文本向量化\n",
        "        query_vector = self.embedding_model.embed_query(query_text)\n",
        "\n",
        "        # 2. 執行向量搜尋\n",
        "        search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
        "        results = self.collection.search(\n",
        "            data=[query_vector],\n",
        "            anns_field=\"embedding\",\n",
        "            param=search_params,\n",
        "            limit=top_k,\n",
        "            output_fields=[\"text\", \"source\"] # 指定要回傳的欄位\n",
        "        )\n",
        "\n",
        "        # 3. 整理並回傳結果\n",
        "        hits = results[0]\n",
        "        return [\n",
        "            {\n",
        "                'id': hit.id,\n",
        "                'distance': hit.distance,\n",
        "                'text': hit.entity.get('text'),\n",
        "                'source': hit.entity.get('source')\n",
        "            }\n",
        "            for hit in hits\n",
        "        ]\n",
        "\n",
        "    def query(self, *args, **kwargs):\n",
        "        # 在這個類別中，我們使用 search 方法進行主要操作\n",
        "        if 'query_text' in kwargs:\n",
        "            return self.search(kwargs['query_text'], kwargs.get('top_k', 5))\n",
        "        return \"請提供 'query_text' 參數。\"\n",
        "\n",
        "    def disconnect(self):\n",
        "        try:\n",
        "            connections.disconnect(\"default\")\n",
        "            print(\"已斷開 Milvus 連接。\")\n",
        "        except Exception as e:\n",
        "            print(f\"斷開 Milvus 連接失敗: {e}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "sf-p0mJDVmpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/RAG/LLM/LLMInitializer.py`**"
      ],
      "metadata": {
        "id": "vUvCyQYGVmpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "class LLMInitializer:\n",
        "    def __init__(self, model_name: str = \"deepseek-coder:33b-instruct\", temperature: float = 0.1):\n",
        "        \"\"\"\n",
        "        初始化 LLM。\n",
        "        :param model_name: 在 Ollama 中運行的模型名稱。\n",
        "        :param temperature: 控制生成文本的隨機性。\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.temperature = temperature\n",
        "        self.llm = None\n",
        "\n",
        "    def get_llm(self):\n",
        "        \"\"\"獲取已初始化的 LLM 實例\"\"\"\n",
        "        if self.llm is None:\n",
        "            try:\n",
        "                self.llm = Ollama(\n",
        "                    model=self.model_name,\n",
        "                    temperature=self.temperature\n",
        "                )\n",
        "                print(f\"成功初始化 Ollama 模型: {self.model_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"初始化 Ollama 模型失敗: {e}\")\n",
        "                # 可以在這裡提供一個備用的 LLM 或拋出異常\n",
        "                raise ConnectionError(\"無法連接到 Ollama 服務。請確保 Ollama 正在運行。\") from e\n",
        "        return self.llm"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "KKtoZJ5SVmpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **`sales_rag_app/libs/RAG/Tools/ContentSpliter.py`**"
      ],
      "metadata": {
        "id": "9xgTUCXqVmpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
        "\n",
        "class ContentSplitter:\n",
        "    def __init__(self, chunk_size=1000, chunk_overlap=100):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.default_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=self.chunk_size,\n",
        "            chunk_overlap=self.chunk_overlap\n",
        "        )\n",
        "        self.md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n",
        "            (\"#\", \"Header 1\"),\n",
        "            (\"##\", \"Header 2\"),\n",
        "            (\"###\", \"Header 3\"),\n",
        "        ])\n",
        "\n",
        "    def split_text(self, text: str, file_type: str = 'txt'):\n",
        "        \"\"\"\n",
        "        根據檔案類型分割文本\n",
        "        :param text: 要分割的文本\n",
        "        :param file_type: 'txt' 或 'md'\n",
        "        :return: 分割後的文本區塊列表\n",
        "        \"\"\"\n",
        "        if file_type.lower() == 'md':\n",
        "            # 對於 Markdown，先按標題分割，再對長段落進行遞迴分割\n",
        "            md_chunks = self.md_splitter.split_text(text)\n",
        "            final_chunks = []\n",
        "            for chunk in md_chunks:\n",
        "                if len(chunk.page_content) > self.chunk_size:\n",
        "                    sub_chunks = self.default_splitter.create_documents([chunk.page_content])\n",
        "                    # 將元數據加回去\n",
        "                    for sub_chunk in sub_chunks:\n",
        "                        sub_chunk.metadata.update(chunk.metadata)\n",
        "                    final_chunks.extend(sub_chunks)\n",
        "                else:\n",
        "                    final_chunks.append(chunk)\n",
        "            return final_chunks\n",
        "        else:\n",
        "            return self.default_splitter.create_documents([text])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Cmvwz-EQVmpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### \\#\\# 4. 前端介面 (HTML/CSS/JS)\n",
        "\n",
        "#### **`sales_rag_app/templates/index.html`**\n",
        "\n",
        "```html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"zh-Hant\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>AI 筆記型電腦銷售助理</title>\n",
        "    <link rel=\"stylesheet\" href=\"/static/css/style.css\">\n",
        "    <script src=\"[https://cdn.jsdelivr.net/npm/marked/marked.min.js](https://cdn.jsdelivr.net/npm/marked/marked.min.js)\"></script>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"app-container\">\n",
        "        <header class=\"app-header\">\n",
        "            <h1>AI 筆記型電腦銷售助理</h1>\n",
        "            <p>您的專業產品比較與問題解答幫手</p>\n",
        "        </header>\n",
        "        <main class=\"chat-main-container\">\n",
        "            {% include 'chat/ai-chat-content.html' %}\n",
        "        </main>\n",
        "    </div>\n",
        "    <script src=\"/static/js/ai-chat.js\"></script>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "#### **`sales_rag_app/templates/chat/ai-chat-content.html`**\n",
        "\n",
        "```html\n",
        "<div class=\"chat-container\">\n",
        "    <div class=\"chat-box\" id=\"chat-box\">\n",
        "        <div class=\"message-bubble assistant\">\n",
        "            <div class=\"message-content\">\n",
        "                <p>您好！我是您的 AI 銷售助理。我可以回答關於 **AG958** 和 **AKK839** 筆記型電腦的問題，並為您進行比較。</p>\n",
        "                <p>您可以試著問：</p>\n",
        "                <ul>\n",
        "                    <li>AG958 和 AKK839 的散熱設計有什麼不同？</li>\n",
        "                    <li>哪台筆電的電池續航力比較好？</li>\n",
        "                    <li>AKK839 的主要特色是什麼？</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    <div class=\"chat-input-area\">\n",
        "        <form id=\"chat-form\">\n",
        "            <textarea id=\"user-input\" placeholder=\"在這裡輸入您的問題...\" rows=\"1\"></textarea>\n",
        "            <button id=\"send-button\" type=\"submit\">\n",
        "                <svg xmlns=\"[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"feather feather-send\"><line x1=\"22\" y1=\"2\" x2=\"11\" y2=\"13\"></line><polygon points=\"22 2 15 22 11 13 2 9 22 2\"></polygon></svg>\n",
        "            </button>\n",
        "        </form>\n",
        "    </div>\n",
        "</div>\n",
        "```\n",
        "\n",
        "#### **`sales_rag_app/static/css/style.css`**\n",
        "\n",
        "```css\n",
        ":root {\n",
        "    --bg-color: #f0f2f5;\n",
        "    --app-bg: #ffffff;\n",
        "    --chat-bg: #f7f7f7;\n",
        "    --user-bubble-bg: #007bff;\n",
        "    --assistant-bubble-bg: #e9ecef;\n",
        "    --text-color: #212529;\n",
        "    --user-text-color: #ffffff;\n",
        "    --assistant-text-color: #212529;\n",
        "    --border-color: #dee2e6;\n",
        "    --shadow-color: rgba(0, 0, 0, 0.1);\n",
        "}\n",
        "\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif;\n",
        "    margin: 0;\n",
        "    padding: 0;\n",
        "    background-color: var(--bg-color);\n",
        "    color: var(--text-color);\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    height: 100vh;\n",
        "}\n",
        "\n",
        ".app-container {\n",
        "    width: 100%;\n",
        "    max-width: 800px;\n",
        "    height: 95vh;\n",
        "    background-color: var(--app-bg);\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 4px 12px var(--shadow-color);\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    overflow: hidden;\n",
        "}\n",
        "\n",
        ".app-header {\n",
        "    padding: 1rem 1.5rem;\n",
        "    border-bottom: 1px solid var(--border-color);\n",
        "    background-color: var(--app-bg);\n",
        "}\n",
        "\n",
        ".app-header h1 {\n",
        "    margin: 0;\n",
        "    font-size: 1.5rem;\n",
        "}\n",
        "\n",
        ".app-header p {\n",
        "    margin: 0.25rem 0 0;\n",
        "    color: #6c757d;\n",
        "}\n",
        "\n",
        ".chat-main-container {\n",
        "    flex-grow: 1;\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    overflow: hidden;\n",
        "}\n",
        "\n",
        ".chat-container {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    height: 100%;\n",
        "    background-color: var(--chat-bg);\n",
        "}\n",
        "\n",
        ".chat-box {\n",
        "    flex-grow: 1;\n",
        "    overflow-y: auto;\n",
        "    padding: 1.5rem;\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    gap: 1rem;\n",
        "}\n",
        "\n",
        ".message-bubble {\n",
        "    max-width: 80%;\n",
        "    padding: 0.75rem 1rem;\n",
        "    border-radius: 18px;\n",
        "    word-wrap: break-word;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        ".message-bubble.user {\n",
        "    background-color: var(--user-bubble-bg);\n",
        "    color: var(--user-text-color);\n",
        "    align-self: flex-end;\n",
        "    border-bottom-right-radius: 4px;\n",
        "}\n",
        "\n",
        ".message-bubble.assistant {\n",
        "    background-color: var(--assistant-bubble-bg);\n",
        "    color: var(--assistant-text-color);\n",
        "    align-self: flex-start;\n",
        "    border-bottom-left-radius: 4px;\n",
        "}\n",
        "\n",
        ".message-bubble.thinking {\n",
        "    color: #6c757d;\n",
        "}\n",
        "\n",
        ".message-bubble.thinking::after {\n",
        "    content: '...';\n",
        "    display: inline-block;\n",
        "    animation: thinking-dots 1.5s infinite;\n",
        "}\n",
        "\n",
        "@keyframes thinking-dots {\n",
        "    0%, 20% { content: '.'; }\n",
        "    40%, 60% { content: '..'; }\n",
        "    80%, 100% { content: '...'; }\n",
        "}\n",
        "\n",
        "\n",
        ".message-content table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    margin: 1rem 0;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".message-content th, .message-content td {\n",
        "    border: 1px solid var(--border-color);\n",
        "    padding: 0.5rem;\n",
        "    text-align: left;\n",
        "}\n",
        "\n",
        ".message-content th {\n",
        "    background-color: #f8f9fa;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".message-content h3 {\n",
        "    margin-top: 1rem;\n",
        "    margin-bottom: 0.5rem;\n",
        "    font-size: 1.1em;\n",
        "    color: var(--user-bubble-bg);\n",
        "}\n",
        "\n",
        ".message-content details {\n",
        "    margin-top: 1rem;\n",
        "    border: 1px solid var(--border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 0.5rem;\n",
        "}\n",
        "\n",
        ".message-content summary {\n",
        "    cursor: pointer;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".message-content blockquote {\n",
        "    border-left: 3px solid var(--border-color);\n",
        "    padding-left: 1rem;\n",
        "    margin-left: 0;\n",
        "    color: #6c757d;\n",
        "    font-style: italic;\n",
        "}\n",
        "\n",
        "\n",
        ".chat-input-area {\n",
        "    padding: 1rem 1.5rem;\n",
        "    border-top: 1px solid var(--border-color);\n",
        "    background-color: var(--app-bg);\n",
        "}\n",
        "\n",
        "#chat-form {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    gap: 0.5rem;\n",
        "}\n",
        "\n",
        "#user-input {\n",
        "    flex-grow: 1;\n",
        "    padding: 0.75rem;\n",
        "    border: 1px solid var(--border-color);\n",
        "    border-radius: 20px;\n",
        "    resize: none;\n",
        "    font-size: 1rem;\n",
        "    line-height: 1.5;\n",
        "    max-height: 120px;\n",
        "    overflow-y: auto;\n",
        "}\n",
        "\n",
        "#user-input:focus {\n",
        "    outline: none;\n",
        "    border-color: var(--user-bubble-bg);\n",
        "    box-shadow: 0 0 0 2px rgba(0, 123, 255, 0.25);\n",
        "}\n",
        "\n",
        "#send-button {\n",
        "    background-color: var(--user-bubble-bg);\n",
        "    border: none;\n",
        "    color: white;\n",
        "    width: 40px;\n",
        "    height: 40px;\n",
        "    border-radius: 50%;\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.2s;\n",
        "}\n",
        "\n",
        "#send-button:hover {\n",
        "    background-color: #0056b3;\n",
        "}\n",
        "\n",
        "#send-button:disabled {\n",
        "    background-color: #6c757d;\n",
        "    cursor: not-allowed;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "#### **`sales_rag_app/static/js/ai-chat.js`**\n",
        "\n",
        "```javascript\n",
        "document.addEventListener(\"DOMContentLoaded\", () => {\n",
        "    const chatForm = document.getElementById(\"chat-form\");\n",
        "    const userInput = document.getElementById(\"user-input\");\n",
        "    const sendButton = document.getElementById(\"send-button\");\n",
        "    const chatBox = document.getElementById(\"chat-box\");\n",
        "\n",
        "    // 自動調整輸入框高度\n",
        "    userInput.addEventListener(\"input\", () => {\n",
        "        userInput.style.height = \"auto\";\n",
        "        userInput.style.height = `${userInput.scrollHeight}px`;\n",
        "    });\n",
        "\n",
        "    chatForm.addEventListener(\"submit\", async (e) => {\n",
        "        e.preventDefault();\n",
        "        const query = userInput.value.trim();\n",
        "        if (!query) return;\n",
        "\n",
        "        // 清空輸入框並重設高度\n",
        "        userInput.value = \"\";\n",
        "        userInput.style.height = \"auto\";\n",
        "\n",
        "        // 顯示使用者訊息\n",
        "        appendMessage(query, \"user\");\n",
        "\n",
        "        // 禁用傳送按鈕\n",
        "        sendButton.disabled = true;\n",
        "\n",
        "        // 顯示\"思考中\"訊息\n",
        "        const thinkingBubble = appendMessage(\"AI 正在思考中\", \"assistant thinking\");\n",
        "\n",
        "        try {\n",
        "            const response = await fetch(\"/api/chat-stream\", {\n",
        "                method: \"POST\",\n",
        "                headers: { \"Content-Type\": \"application/json\" },\n",
        "                body: JSON.stringify({ query: query, service_name: \"sales_assistant\" })\n",
        "            });\n",
        "\n",
        "            if (!response.ok) {\n",
        "                const errorData = await response.json();\n",
        "                throw new Error(errorData.error || \"請求失敗\");\n",
        "            }\n",
        "\n",
        "            const reader = response.body.getReader();\n",
        "            const decoder = new TextDecoder();\n",
        "            let done = false;\n",
        "\n",
        "            // 清空\"思考中\"的內容，準備接收串流\n",
        "            thinkingBubble.classList.remove(\"thinking\");\n",
        "            const responseContent = thinkingBubble.querySelector('.message-content');\n",
        "            responseContent.innerHTML = \"\";\n",
        "\n",
        "            while (!done) {\n",
        "                const { value, done: readerDone } = await reader.read();\n",
        "                done = readerDone;\n",
        "                const chunk = decoder.decode(value, { stream: true });\n",
        "                \n",
        "                // 處理 SSE 數據\n",
        "                const lines = chunk.split('\\n\\n');\n",
        "                for (const line of lines) {\n",
        "                    if (line.startsWith('data: ')) {\n",
        "                        const jsonDataString = line.substring(6);\n",
        "                        if (jsonDataString) {\n",
        "                            try {\n",
        "                                const jsonData = JSON.parse(jsonDataString);\n",
        "                                renderResponse(responseContent, jsonData);\n",
        "                            } catch (e) {\n",
        "                                console.error(\"解析 JSON 失敗:\", e, \"Data:\", jsonDataString);\n",
        "                                responseContent.innerHTML += \"<p style='color:red;'>回應格式錯誤。</p>\";\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        } catch (error) {\n",
        "            console.error(\"聊天請求錯誤:\", error);\n",
        "            const errorContent = thinkingBubble.querySelector('.message-content');\n",
        "            errorContent.innerHTML = `<p style='color:red;'>抱歉，發生錯誤：${error.message}</p>`;\n",
        "        } finally {\n",
        "            sendButton.disabled = false;\n",
        "            userInput.focus();\n",
        "        }\n",
        "    });\n",
        "\n",
        "    function appendMessage(text, type) {\n",
        "        const messageBubble = document.createElement(\"div\");\n",
        "        messageBubble.className = `message-bubble ${type}`;\n",
        "        \n",
        "        const messageContent = document.createElement(\"div\");\n",
        "        messageContent.className = \"message-content\";\n",
        "        messageContent.innerText = text;\n",
        "\n",
        "        messageBubble.appendChild(messageContent);\n",
        "        chatBox.appendChild(messageBubble);\n",
        "        chatBox.scrollTop = chatBox.scrollHeight;\n",
        "        return messageBubble;\n",
        "    }\n",
        "\n",
        "    function renderResponse(container, data) {\n",
        "        if (data.error) {\n",
        "            container.innerHTML = `<p class='error'>助理發生錯誤: ${data.error}</p>`;\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        let markdownString = \"\";\n",
        "\n",
        "        if (data.answer_summary) {\n",
        "            markdownString += `### 回答摘要\\n${data.answer_summary}\\n\\n`;\n",
        "        }\n",
        "\n",
        "        if (data.comparison_table && data.comparison_table.length > 0) {\n",
        "            markdownString += `### 規格比較\\n\\n`;\n",
        "            markdownString += `| 特性 | AG958 | AKK839 |\\n`;\n",
        "            markdownString += `|:---|:---|:---|\\n`;\n",
        "            data.comparison_table.forEach(row => {\n",
        "                markdownString += `| ${row.feature || 'N/A'} | ${row.AG958 || 'N/A'} | ${row.AKK839 || 'N/A'} |\\n`;\n",
        "            });\n",
        "            markdownString += `\\n`;\n",
        "        }\n",
        "\n",
        "        if (data.conclusion) {\n",
        "            markdownString += `### 結論建議\\n${data.conclusion}\\n\\n`;\n",
        "        }\n",
        "        \n",
        "        if (data.source_references && data.source_references.length > 0) {\n",
        "            markdownString += `<details><summary>參考資料來源</summary>\\n\\n`;\n",
        "            data.source_references.forEach(source => {\n",
        "                const cleanedSource = source.replace(/[\\r\\n]+/g, ' ').trim();\n",
        "                if(cleanedSource) {\n",
        "                    markdownString += `> ${cleanedSource}\\n\\n`;\n",
        "                }\n",
        "            });\n",
        "            markdownString += `</details>`;\n",
        "        }\n",
        "        \n",
        "        // 使用 marked.js 將 Markdown 渲染為 HTML\n",
        "        container.innerHTML = marked.parse(markdownString);\n",
        "        chatBox.scrollTop = chatBox.scrollHeight;\n",
        "    }\n",
        "});\n",
        "\n",
        "```\n",
        "\n",
        "#### **`sales_rag_app/static/js/marked.min.js`**\n",
        "\n",
        "請從 [Marked.js CDN](https://www.google.com/url?sa=E&source=gmail&q=https://cdn.jsdelivr.net/npm/marked/marked.min.js) 下載 `marked.min.js` 檔案，並將其放置在此目錄中。這是將 Markdown 語法轉換為 HTML 的必要函式庫。\n",
        "\n",
        "-----\n",
        "\n",
        "### \\#\\# 5. 如何執行專案\n",
        "\n",
        "1.  **安裝依賴**：\n",
        "\n",
        "    ```bash\n",
        "    pip install -r requirements.txt\n",
        "    ```\n",
        "\n",
        "2.  **啟動 Docker 服務**：\n",
        "    在專案根目錄執行以下指令，以啟動 Milvus。\n",
        "\n",
        "    ```bash\n",
        "    docker-compose up -d\n",
        "    ```\n",
        "\n",
        "    初次啟動需要一些時間下載映像檔。\n",
        "\n",
        "3.  **導入資料**：\n",
        "    執行資料導入腳本。請確保您的 `data` 目錄下有正確的檔案。\n",
        "\n",
        "    ```bash\n",
        "    python ingest_data.py\n",
        "    ```\n",
        "\n",
        "    您應該會看到處理進度的訊息。\n",
        "\n",
        "4.  **啟動 FastAPI 應用**：\n",
        "\n",
        "    ```bash\n",
        "    uvicorn sales_rag_app.main:app --reload\n",
        "    ```\n",
        "\n",
        "5.  **開啟網頁**：\n",
        "    在您的瀏覽器中開啟 `http://127.0.0.1:8000`，即可開始與您的 AI 銷售助理互動。\n",
        "\n",
        "這個完整的專案結構和程式碼為您提供了一個功能齊全、可擴充的 RAG 應用程式，專為您的銷售場景量身打造。"
      ],
      "metadata": {
        "id": "dtmJFchIVmpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://github.com/QwertPan/compact-watsonx-ai-incubation-program\">https://github.com/QwertPan/compact-watsonx-ai-incubation-program</a></li>\n",
        "  <li><a href=\"https://github.com/tanlandy/rag\">https://github.com/tanlandy/rag</a></li>\n",
        "  <li><a href=\"https://github.com/labiium/vectoriium\">https://github.com/labiium/vectoriium</a></li>\n",
        "  <li><a href=\"https://community.ibm.com/community/user/watsonx/blogs/katherine-ciaravalli/2024/07/01/get-started-with-using-ibm-embedding-models-with-w\">https://community.ibm.com/community/user/watsonx/blogs/katherine-ciaravalli/2024/07/01/get-started-with-using-ibm-embedding-models-with-w</a></li>\n",
        "  <li><a href=\"https://github.com/ankaji92/LaughingManFastAPI\">https://github.com/ankaji92/LaughingManFastAPI</a></li>\n",
        "  <li><a href=\"https://github.com/OUMontiel/Proiectus\">https://github.com/OUMontiel/Proiectus</a></li>\n",
        "  <li><a href=\"https://github.com/PaoloPaone12/build_ctf\">https://github.com/PaoloPaone12/build_ctf</a></li>\n",
        "  <li><a href=\"https://github.com/AlI230/HomeCloud\">https://github.com/AlI230/HomeCloud</a></li>\n",
        "  <li><a href=\"https://juejin.cn/post/7383268946818727951\">https://juejin.cn/post/7383268946818727951</a></li>\n",
        "  <li><a href=\"https://github.com/ayanazmyy/Bankist\">https://github.com/ayanazmyy/Bankist</a></li>\n",
        "  <li><a href=\"https://github.com/sinaetown/Calendar\">https://github.com/sinaetown/Calendar</a></li>\n",
        "  <li><a href=\"https://github.com/duaashabanali/MeDoc\">https://github.com/duaashabanali/MeDoc</a></li>\n",
        "  <li><a href=\"https://github.com/Hyunku-Shin/chatbot-app-project\">https://github.com/Hyunku-Shin/chatbot-app-project</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "W2WpHPF5VmpC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}